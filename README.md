# yPyTorch

ç®€æ˜“ç‰ˆ PyTorch å®ç°ï¼Œç”¨äºå­¦ä¹ æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ ¸å¿ƒåŸç†ã€‚

## é¡¹ç›®çŠ¶æ€

âœ… **Phase 1 å®Œæˆ**: åŸºç¡€ Tensor å®ç°
- [x] æ ¸å¿ƒ Tensor ç±»
- [x] åŸºç¡€æ•°æ®ç±»å‹æ”¯æŒ
- [x] åº•å±‚å­˜å‚¨å®ç°
- [x] åŸºç¡€æ•°å­¦è¿ç®—
- [x] å½’çº¦æ“ä½œ
- [x] å½¢çŠ¶æ“ä½œï¼ˆreshape, transposeï¼‰
- [x] ç´¢å¼•å’Œåˆ‡ç‰‡

âœ… **Phase 2 å®Œæˆ**: è‡ªåŠ¨æ±‚å¯¼ç³»ç»Ÿ
- [x] Function åŸºç±»ï¼ˆè®¡ç®—å›¾èŠ‚ç‚¹ï¼‰
- [x] åå‘ä¼ æ’­å¼•æ“
- [x] å¸¸ç”¨æ“ä½œçš„æ¢¯åº¦å‡½æ•°ï¼ˆadd, mul, sub, div, matmul, sum, exp, log, pow ç­‰ï¼‰
- [x] é“¾å¼æ³•åˆ™æ”¯æŒ
- [x] æ¢¯åº¦ç´¯ç§¯

âœ… **Phase 3 å®Œæˆ**: ç¥ç»ç½‘ç»œæ¨¡å—
- [x] Module åŸºç±»
- [x] Linear å±‚ï¼ˆå…¨è¿æ¥å±‚ï¼‰
- [x] æ¿€æ´»å‡½æ•°ï¼ˆReLU, Sigmoid, Tanhï¼‰
- [x] æŸå¤±å‡½æ•°ï¼ˆMSE, CrossEntropyï¼‰
- [x] å‚æ•°åˆå§‹åŒ–ï¼ˆXavier, Normalï¼‰
- [x] å‚æ•°ç®¡ç†å’Œæ¢¯åº¦æ¸…é›¶

âœ… **Phase 4 å®Œæˆ**: ä¼˜åŒ–å™¨
- [x] Optimizer åŸºç±»
- [x] SGD ä¼˜åŒ–å™¨ï¼ˆæ”¯æŒåŠ¨é‡å’Œæƒé‡è¡°å‡ï¼‰
- [x] Adam ä¼˜åŒ–å™¨ï¼ˆè‡ªé€‚åº”å­¦ä¹ ç‡ï¼‰
- [x] çŠ¶æ€ç®¡ç†å’Œå‚æ•°æ›´æ–°

ğŸš§ **è¿›è¡Œä¸­**: Phase 5 - å®Œæ•´è®­ç»ƒç¤ºä¾‹

## å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/yPyTorch.git
cd yPyTorch

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### åŸºç¡€ä½¿ç”¨

```python
import ypytorch as ypt

# åˆ›å»ºå¼ é‡
x = ypt.tensor([1.0, 2.0, 3.0])
y = ypt.tensor([4.0, 5.0, 6.0])

# å¼ é‡è¿ç®—
z = x + y
print(z)  # Tensor([5.0, 7.0, 9.0])

# çŸ©é˜µè¿ç®—
a = ypt.tensor([[1.0, 2.0], [3.0, 4.0]])
b = ypt.tensor([[5.0, 6.0], [7.0, 8.0]])
c = a @ b
print(c)

# å½’çº¦æ“ä½œ
t = ypt.tensor([[1.0, 2.0], [3.0, 4.0]])
print(t.sum())  # 10.0
print(t.mean())  # 2.5

# è‡ªåŠ¨æ±‚å¯¼
x = ypt.tensor([2.0, 3.0], requires_grad=True)
y = x * 2
z = y.sum()
z.backward()
print(x.grad)  # [2.0, 2.0]

# å®Œæ•´è®­ç»ƒæµç¨‹
model = ypt.nn.Linear(2, 1)
criterion = ypt.nn.MSELoss()
optimizer = ypt.optim.SGD(model.parameters(), lr=0.01)

# è®­ç»ƒå¾ªç¯
for epoch in range(100):
    y_pred = model(x)
    loss = criterion(y_pred, y_true)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

### è¿è¡Œç¤ºä¾‹

```bash
python examples/basic_usage.py
```

### è¿è¡Œæµ‹è¯•

```bash
pytest tests/ -v
```

## é¡¹ç›®ç»“æ„

```
ypytorch/
â”œâ”€â”€ core/              # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ tensor.py     # Tensor ç±»
â”‚   â”œâ”€â”€ storage.py    # åº•å±‚å­˜å‚¨
â”‚   â””â”€â”€ dtype.py      # æ•°æ®ç±»å‹
â”œâ”€â”€ ops/              # æ“ä½œç¬¦
â”‚   â”œâ”€â”€ math.py       # æ•°å­¦è¿ç®—
â”‚   â””â”€â”€ reduction.py  # å½’çº¦æ“ä½œ
â”œâ”€â”€ autograd/         # è‡ªåŠ¨æ±‚å¯¼ï¼ˆå¼€å‘ä¸­ï¼‰
â”œâ”€â”€ nn/               # ç¥ç»ç½‘ç»œï¼ˆè®¡åˆ’ä¸­ï¼‰
â””â”€â”€ optim/            # ä¼˜åŒ–å™¨ï¼ˆè®¡åˆ’ä¸­ï¼‰

docs/                 # æ–‡æ¡£
examples/             # ç¤ºä¾‹ä»£ç 
tests/                # æµ‹è¯•æ–‡ä»¶
```

## æ–‡æ¡£

è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ [docs/](./docs/) ç›®å½•ï¼š

- [æ¶æ„è®¾è®¡](./docs/ARCHITECTURE.md) - é¡¹ç›®æ•´ä½“æ¶æ„
- [å¼€å‘è·¯çº¿å›¾](./docs/ROADMAP.md) - è¯¦ç»†çš„å¼€å‘è®¡åˆ’
- [API è®¾è®¡](./docs/API_DESIGN.md) - API è®¾è®¡è§„èŒƒ

## å¼€å‘è®¡åˆ’

- [x] Phase 1: åŸºç¡€ Tensor å®ç°
- [x] Phase 2: è‡ªåŠ¨æ±‚å¯¼ç³»ç»Ÿ
- [x] Phase 3: ç¥ç»ç½‘ç»œæ¨¡å—
- [x] Phase 4: ä¼˜åŒ–å™¨
- [x] Phase 5: å®Œæ•´è®­ç»ƒç¤ºä¾‹

## å­¦ä¹ ç›®æ ‡

é€šè¿‡å®ç° yPyTorchï¼Œä½ å°†å­¦ä¹ åˆ°ï¼š

1. **å¼ é‡çš„åº•å±‚å®ç°** - ç†è§£å¤šç»´æ•°ç»„çš„å­˜å‚¨å’Œæ“ä½œ
2. **è‡ªåŠ¨æ±‚å¯¼åŸç†** - ç†è§£åå‘ä¼ æ’­å’Œè®¡ç®—å›¾
3. **ç¥ç»ç½‘ç»œæ„å»º** - ç†è§£å±‚ã€æ¿€æ´»å‡½æ•°ã€æŸå¤±å‡½æ•°
4. **ä¼˜åŒ–ç®—æ³•** - ç†è§£ SGDã€Adam ç­‰ä¼˜åŒ–å™¨

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

MIT License
